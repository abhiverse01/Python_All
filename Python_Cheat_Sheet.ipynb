{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python Cheat-Sheet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhiverse01/Python_All/blob/main/Python_Cheat_Sheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdcZpTVhENOe"
      },
      "source": [
        "#Python Cheatsheet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZM0TBe-ESJj"
      },
      "source": [
        "##Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC7dGjwjEMwe"
      },
      "source": [
        "#Importing Data\n",
        "pd.read_csv(filename) # From a CSV file\n",
        "pd.read_table(filename) # From a delimited text file (like TSV)\n",
        "pd.read_excel(filename) # From an Excel file\n",
        "pd.read_sql(query, connection_object) # Reads from a SQL table/database\n",
        "pd.read_json(json_string) # Reads from a JSON formatted string, URL or file.\n",
        "pd.read_html(url) # Parses an html URL, string or file and extracts tables to a list of dataframes\n",
        "pd.read_clipboard() # Takes the contents of your clipboard and passes it to read_table()\n",
        "pd.DataFrame(dict) # From a dict, keys for columns names, values for data as lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQfyl7HIEqBc"
      },
      "source": [
        "##Exploring Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTUOi_GFEqg1"
      },
      "source": [
        "#Exploring Data\n",
        "df.shape() # Prints number of rows and columns in dataframe\n",
        "df.head(n) # Prints first n rows of the DataFrame\n",
        "df.tail(n) # Prints last n rows of the DataFrame\n",
        "df.info() # Index, Datatype and Memory information\n",
        "df.describe() # Summary statistics for numerical columns\n",
        "s.value_counts(dropna=False) # Views unique values and counts\n",
        "df.apply(pd.Series.value_counts) # Unique values and counts for all columns\n",
        "df.describe() # Summary statistics for numerical columns\n",
        "df.mean() # Returns the mean of all columns\n",
        "df.corr() # Returns the correlation between columns in a DataFrame\n",
        "df.count() # Returns the number of non-null values in each DataFrame column\n",
        "df.max() # Returns the highest value in each column\n",
        "df.min() # Returns the lowest value in each column\n",
        "df.median() # Returns the median of each column\n",
        "df.std() # Returns the standard deviation of each column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYluxI-vErEW"
      },
      "source": [
        "##Selecting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V2X_cNPErOV"
      },
      "source": [
        "#selecting Data\n",
        "df[col] # Returns column with label col as Series\n",
        "df[[col1, col2]] # Returns Columns as a new DataFrame\n",
        "s.iloc[0] # Selection by position (selects first element)\n",
        "s.loc[0] # Selection by index (selects element at index 0)\n",
        "df.iloc[0,:] # First row\n",
        "df.iloc[0,0] # First element of first column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUg0kRzuErY8"
      },
      "source": [
        "##Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH0XZjXGEris"
      },
      "source": [
        "#Data Cleaning\n",
        "df.columns = ['a','b','c'] # Renames columns\n",
        "pd.isnull() # Checks for null Values, Returns Boolean Array\n",
        "pd.notnull() # Opposite of s.isnull()\n",
        "df.dropna() # Drops all rows that contain null values\n",
        "df.dropna(axis=1) # Drops all columns that contain null values\n",
        "df.dropna(axis=1,thresh=n) # Drops all rows have have less than n non null values\n",
        "df.fillna(x) # Replaces all null values with x\n",
        "s.fillna(s.mean()) # Replaces all null values with the mean (mean can be replaced with almost any function from the statistics section)\n",
        "s.astype(float) # Converts the datatype of the series to float\n",
        "s.replace(1,'one') # Replaces all values equal to 1 with 'one'\n",
        "s.replace([1,3],['one','three']) # Replaces all 1 with 'one' and 3 with 'three'\n",
        "df.rename(columns=lambda x: x + 1) # Mass renaming of columns\n",
        "df.rename(columns={'old_name': 'new_ name'}) # Selective renaming\n",
        "df.set_index('column_one') # Changes the index\n",
        "df.rename(index=lambda x: x + 1) # Mass renaming of index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-qdaOHLErsb"
      },
      "source": [
        "##Filter, Sort and Group By"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab60n7ylEr2Q"
      },
      "source": [
        "#Filter, Sort and Group By\n",
        "df[df[col] > 0.5] # Rows where the col column is greater than 0.5\n",
        "df[(df[col] > 0.5) & (df[col] < 0.7)] # Rows where 0.5 < col < 0.7\n",
        "df.sort_values(col1) # Sorts values by col1 in ascending order\n",
        "df.sort_values(col2,ascending=False) # Sorts values by col2 in descending order\n",
        "df.sort_values([col1,col2], ascending=[True,False]) # Sorts values by col1 in ascending order then col2 in descending order\n",
        "df.groupby(col) # Returns a groupby object for values from one column\n",
        "df.groupby([col1,col2]) # Returns a groupby object values from multiple columns\n",
        "df.groupby(col1)[col2].mean() # Returns the mean of the values in col2, grouped by the values in col1 (mean can be replaced with almost any function from the statistics section)\n",
        "df.pivot_table(index=col1, values= col2,col3], aggfunc=mean) # Creates a pivot table that groups by col1 and calculates the mean of col2 and col3\n",
        "df.groupby(col1).agg(np.mean) # Finds the average across all columns for every unique column 1 group\n",
        "df.apply(np.mean) # Applies a function across each column\n",
        "df.apply(np.max, axis=1) # Applies a function across each row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD-sey50EsAP"
      },
      "source": [
        "##Joining and Combining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCI8uclrEsLy"
      },
      "source": [
        "#Joining and Combining\n",
        "df1.append(df2) # Adds the rows in df1 to the end of df2 (columns should be identical)\n",
        "pd.concat([df1, df2],axis=1) # Adds the columns in df1 to the end of df2 (rows should be identical)\n",
        "df1.join(df2,on=col1,how='inner') # SQL-style joins the columns in df1 with the columns on df2 where the rows for col have identical values. how can be one of 'left', 'right', 'outer', 'inner'<strong> </strong>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EU2LRq7EsXg"
      },
      "source": [
        "##Writing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KvauAAbEsht"
      },
      "source": [
        "#Writing Data\n",
        "df.to_csv(filename) # Writes to a CSV file\n",
        "df.to_excel(filename) # Writes to an Excel file\n",
        "df.to_sql(table_name, connection_object) # Writes to a SQL table\n",
        "df.to_json(filename) # Writes to a file in JSON format\n",
        "df.to_html(filename) # Saves as an HTML table\n",
        "df.to_clipboard() # Writes to the clipboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY1TYM6-FhCU"
      },
      "source": [
        "##Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxfIh2RTFhL2"
      },
      "source": [
        "# Import libraries and modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "# Load red wine data.\n",
        "dataset_url = 'http://mlr.cs.umass.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
        "data = pd.read_csv(dataset_url, sep=';')\n",
        "\n",
        "# Split data into training and test sets\n",
        "y = data.quality\n",
        "X = data.drop('quality', axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=123,\n",
        "                                                    stratify=y)\n",
        "\n",
        "# Declare data preprocessing steps\n",
        "pipeline = make_pipeline(preprocessing.StandardScaler(),\n",
        "                         RandomForestRegressor(n_estimators=100))\n",
        "\n",
        "# Declare hyperparameters to tune\n",
        "hyperparameters = { 'randomforestregressor__max_features' : ['auto', 'sqrt', 'log2'],\n",
        "                  'randomforestregressor__max_depth': [None, 5, 3, 1]}\n",
        "\n",
        "# Tune model using cross-validation pipeline\n",
        "clf = GridSearchCV(pipeline, hyperparameters, cv=10)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Refit on the entire training set\n",
        "# No additional code needed if clf.refit == True (default is True)\n",
        "\n",
        "# Evaluate model pipeline on test data\n",
        "pred = clf.predict(X_test)\n",
        "print r2_score(y_test, pred)\n",
        "print mean_squared_error(y_test, pred)\n",
        "\n",
        "# Save model for future use\n",
        "joblib.dump(clf, 'rf_regressor.pkl')\n",
        "# To load: clf2 = joblib.load('rf_regressor.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At9EE41kFhU6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hglj8O53Fhed"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od33yl6oFhnV"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOs0jdx1FhwB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}